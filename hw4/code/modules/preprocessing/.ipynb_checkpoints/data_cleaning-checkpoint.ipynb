{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "This document describes the process by which raw data (particuarly the features) is cleaned and exceptional entries handled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependency and data import\n",
    "Below is the code that imported raw data using `pd.read_csv()`.\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mxnet import nd\n",
    "from preprocessing import *\n",
    "\n",
    "train = pd.read_csv(\"./data/raw/kaggle_house_pred_train.csv\")\n",
    "test_features = pd.read_csv(\"./data/raw/kaggle_house_pred_test.csv\")\n",
    "\n",
    "# Remove response variable from train\n",
    "train_features = train[list(train)[:-1]]\n",
    "# Concatenate the feature matrices\n",
    "all_features = pd.concat([train_features, test_features], axis=0)\n",
    "all_features = all_features.reset_index(drop=True)\n",
    "# To help with easier do, replace all NULL value by np.nan\n",
    "all_features = all_features.fillna(np.nan)\n",
    "```\n",
    "Note that the last line unified all NULL values to `np.nan`, whereas previously some NULL values are not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSSubClass\n",
    "`MSSubClass` is read by `pd.read_csv()` as an integer column. However, by the description on Kaggle, this is actually a numerically coded categorical variable. Therefore, this column is changed to `dtype = str` for future one-hot encoding.\n",
    "```python\n",
    "update_dtypes = {\"MSSubClass\": str}\n",
    "all_features = all_features.astype(update_dtypes)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LotFrontage \n",
    "`LotFrontage` describes the length of street connected to the building (?), so it doesn't make sense for a building to have `np.nan` value. All `np.nan` values are replaced by 0.\n",
    "```python\n",
    "all_features.LotFrontage = all_features.LotFrontage.fillna(0)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masonry Veneer\n",
    "`MasVnrType` and `MasVnrArea` respectively include information regarding the type of Masonry Veneer and its size. Because `MasVnrType` has a \"None\" option, it does not make sense to have `np.nan` values within those two columns. All NULL values in `MasVnrType` are replaced by \"None\" and all NULL values in `MasVnrArea` are replaced by 0.\n",
    "```python\n",
    "all_features.MasVnrType = all_features.MasVnrType.fillna(\"None\")\n",
    "all_features.MasVnrArea = all_features.MasVnrArea.fillna(0)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## External Quality and Condition \n",
    "(This is true for all quality and condition columns and will not be repeated below)  \n",
    "`ExterQual` and `ExterCond` are read as categorical columns. However, there exists a column `OverallQual` that establishes a map between a verbal rating and a numerical rating. Therefore, these two columns are converted into numerical columns to express the \"ordering\" information. Note that the lowest possible score on `OverallQual` is 1, so I use 0 to encode a \"NA\" if it is present.\n",
    "```python\n",
    "verbal_rating_dict = {\"Ex\": np.float64(9),\n",
    "                    \"Gd\": np.float64(7),\n",
    "                    \"TA\": np.float64(5),\n",
    "                    \"Fa\": np.float64(3),\n",
    "                    \"Po\": np.float64(2),\n",
    "                    \"NA\": np.float64(0)}\n",
    "def vr_map(verbal_rating):\n",
    "    # If verbal rating is string, return appropriate value\n",
    "    if isinstance(verbal_rating, str):\n",
    "        return verbal_rating_dict[verbal_rating]\n",
    "    else:\n",
    "        return np.nan\n",
    "ext_qual_num = [verbal_rating_dict[token] for\n",
    "                token in all_features.ExterQual.values]\n",
    "ext_cond_num = [verbal_rating_dict[token] for\n",
    "                token in all_features.ExterCond.values]\n",
    "all_features.ExterQual = ext_qual_num\n",
    "all_features.ExterCond = ext_cond_num\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basement \n",
    "There are a number of columns related to basement:  \n",
    "`BsmtCond`, `BsmtQual`, `BsmtExposure`, `BsmtFinType1`, `BsmtFinType2`, `BsmtFinSF1`, `BsmtFinSF2`, `BsmtUnfSF`, `TotalBsmtSF`.  \n",
    "There are rows in which `BsmtQual` is not NULL, but `BsmtCond` is NULL. This is inconsistent because any one of those two being not NULL indicates the existence of a basement. This is resolved by replacing the NULL value by the mode value of the missing-value column for all buildings from the same year built. Similar discrepancy between other pairs of variables is resolved in the same way\n",
    "```python\n",
    "# There are rows in which BsmtQual is not NULL, but BsmtCond is NULL\n",
    "# such NULL values will be replaced by the mode of BsmtCond of buildings\n",
    "# from the same year built\n",
    "row_indices = all_features.query(\"not BsmtQual.isnull() and BsmtCond.isnull()\").index\n",
    "for row_index in row_indices:\n",
    "    # Get the year built\n",
    "    YB = all_features.iloc[row_index].YearBuilt\n",
    "    # Find the mode of BsmtCond\n",
    "    BC_mode = all_features.query(\"YearBuilt == @YB\").BsmtCond.mode()[0]\n",
    "    # replace!\n",
    "    all_features.iloc[row_index, list(all_features).index(\"BsmtCond\")] = BC_mode\n",
    "\n",
    "#   There are tows in which BsmtQual is not NULL but BsmtCond is NULL\n",
    "#   such NULL values will be replaced by the mode of BsmtQual of buildings\n",
    "#   from the same year built\n",
    "row_indices = all_features.query(\"BsmtQual.isnull() and not BsmtCond.isnull()\").index\n",
    "for row_index in row_indices:\n",
    "    # Get the year built\n",
    "    YB = all_features.iloc[row_index].YearBuilt\n",
    "    # Find the mode of BsmtCond\n",
    "    BQ_mode = all_features.query(\"YearBuilt == @YB\").BsmtQual.mode()[0]\n",
    "    # replace!\n",
    "    all_features.iloc[row_index, list(all_features).index(\"BsmtQual\")] = BQ_mode\n",
    "```\n",
    "\n",
    "Then, it does not make sense that `BsmtFinSF1`, `BsmtFinSF2`, `BsmtUnfSF`, and `TotalBsmtSF` have NULL values since not having a basement correspond to any square foortage being 0. Therefore, all NULL values are replaced by 0\n",
    "```python\n",
    "all_features.BsmtFinSF1 = all_features.BsmtFinSF1.fillna(0)\n",
    "all_features.BsmtFinSF2 = all_features.BsmtFinSF2.fillna(0)\n",
    "all_features.BsmtUnfSF = all_features.BsmtUnfSF.fillna(0)\n",
    "all_features.TotalBsmtSF = all_features.TotalBsmtSF.fillna(0)\n",
    "```\n",
    "\n",
    "Finally, convert `BsmtQual` and `BsmtCond` to the appropriate numerical scale.\n",
    "```python\n",
    "all_features.BsmtQual = all_features.BsmtQual.apply(vr_map)\n",
    "all_features.BsmtCond = all_features.BsmtCond.apply(vr_map)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Electrical \n",
    "Although the Kaggle page does not specify an `nan` possibility for this column, there exists 1 row for which `Electrical` is NULL. Such NULL value is replaced by the mode.\n",
    "```python\n",
    "drop_rows = list(all_features.query(\"Electrical.isnull()\").index)\n",
    "E_mode = all_features.Electrical.mode()[0]\n",
    "all_features.iloc[drop_rows, list(all_features).index(\"Electrical\")] = E_mode\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kitchen \n",
    "`KitchenQual` contains NULL values despite `KitchenAbvGr` containing no NULL values. Although a far-stretch, I assume that customers should assume the worst when kitchen information is missing. Therefore, all NULL values in `KitchenQual` are replaced by \"Po\", the lowest quality rating possible. Then `KitchenQual` is converted into numerical scale.\n",
    "```python\n",
    "all_features.KitchenQual = all_features.KitchenQual.fillna(\"Po\")\n",
    "all_features.KitchenQual = all_features.KitchenQual.apply(vr_map)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fireplace\n",
    "`Fireplace` does not contain NULL values. `FireplaceQu` is converted into numerical scale.\n",
    "```python\n",
    "all_features.FireplaceQu = all_features.FireplaceQu.apply(vr_map)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Garage\n",
    "There are a number of columns related to garage:\n",
    "* `GarageType`\n",
    "* `GaragteYrBlt` \n",
    "* `GarageFinish`\n",
    "* `GarageCars`\n",
    "* `GarageArea`\n",
    "* `GarageCond`\n",
    "* `GarageQual`  \n",
    "\n",
    "There exist rows in which `GarageType` is not NULL but `GarageYrBlt` is NULL. Such NULL value is replaced by the value from `YearBuilt` since the year a house is built is most likely the year a garage is built.\n",
    "```python\n",
    "indices = list(all_features.query(\"not GarageType.isnull() and GarageYrBlt.isnull()\").index)\n",
    "GYB_index = list(all_features).index('GarageYrBlt')\n",
    "YB_index = list(all_features).index('YearBuilt')\n",
    "for row_index in indices:\n",
    "    all_features.iloc[row_index, GYB_index] = all_features.iloc[row_index, YB_index]\n",
    "```\n",
    "\n",
    "There exist rows in which `GarageType` is not NULL but `GarageFinish` is NULL. Such NULL value is replaced by the mode value of `GarageFinish` of all rows with the same `GarageYrBlt`.\n",
    "```python\n",
    "indices = list(all_features.query(\"not GarageType.isnull() and GarageFinish.isnull()\").index)\n",
    "target_col = list(all_features).index('GarageFinish')\n",
    "for row_index in indices:\n",
    "    #   Get GarageYrBlt\n",
    "    GYB = all_features.iloc[row_index, GYB_index]\n",
    "    GF_mode = all_features.query(\"GarageYrBlt == @GYB\").iloc[:, target_col].mode()[0]\n",
    "    all_features.iloc[row_index, target_col] = GF_mode\n",
    "```\n",
    "\n",
    "There exist rows in which `GarageType` is not NULL but `GarageCars` is NULL. Such NULL value is replaced by the mode of `GarageCars` of all rows with the same `GarageYrBlt`\n",
    "```python\n",
    "indices = list(all_features.query(\"not GarageType.isnull() and GarageCars.isnull()\").index)\n",
    "target_col = list(all_features).index('GarageCars')\n",
    "for row_index in indices:\n",
    "    #   Get GarageYrBlt\n",
    "    GYB = all_features.iloc[row_index, GYB_index]\n",
    "    GC_mode = all_features.query(\"GarageYrBlt == @GYB\").iloc[:, target_col].mode()[0]\n",
    "    all_features.iloc[row_index, target_col] = GC_mode\n",
    "```\n",
    "\n",
    "A similar treatment is applied to `GarageArea`\n",
    "```python\n",
    "indices = list(all_features.query(\"not GarageType.isnull() and GarageArea.isnull()\").index)\n",
    "target_col = list(all_features).index('GarageArea')\n",
    "for row_index in indices:\n",
    "    #   Get GarageYrBlt\n",
    "    GYB = all_features.iloc[row_index, GYB_index]\n",
    "    GA_mean = all_features.query(\"GarageYrBlt == @GYB\").iloc[:, target_col].mean()\n",
    "    all_features.iloc[row_index, target_col] = GA_mean\n",
    "```\n",
    "\n",
    "Finally, convert `GarageCond` and `GarageQual` into numerical scale\n",
    "```python\n",
    "all_features.GarageCond = all_features.GarageCond.apply(vr_map)\n",
    "all_features.GarageQual = all_features.GarageQual.apply(vr_map)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PoolArea \n",
    "There are rows in which `PoolArea` is greater than 0 but `PoolQC` is NULL. This is resolved by replacing such NULL values by the mean `PoolQC` numerical value after converting the verbal rating into numerical rating.\n",
    "```python\n",
    "all_features.PoolQC = all_features.PoolQC.apply(vr_map)\n",
    "sub_val = all_features.PoolQC.mean()\n",
    "row_indices = list(all_features.query(\"PoolArea > 0 and PoolQC.isnull()\").index)\n",
    "all_features.iloc[row_indices, list(all_features).index(\"PoolQC\")] = sub_val\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MiscFeature and MiscVal \n",
    "There exist rows in which `MiscFeature` is NULL but `MiscVal` is greater than 0. Such NULL values are replaced by \"Othr\".\n",
    "```python\n",
    "row_indices = all_features.query(\"MiscFeature.isnull() and MiscVal > 0\").index\n",
    "all_features.iloc[row_indices,list(all_features).index(\"MiscFeature\")] = \"Othr\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YrSold and MoSold\n",
    "\n",
    "`YrSold` and `MoSold` is consolidated into a single numerical variable that indicates how many months have passed since January of 2006. The new feature is named `SaleTimestamp` and the two original columns are dropped.\n",
    "```python\n",
    "all_features[\"SaleTimestamp\"] = (all_features.YrSold - 2006)*12 + all_features.MoSold\n",
    "all_features = all_features.drop([\"YrSold\", \"MoSold\"], axis=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot and normalization\n",
    "Convert all categorical variables at this time into one-hot encoding and drop the original column\n",
    "```python\n",
    "cat_colnames = list(all_features.dtypes[all_features.dtypes == 'object'].index)\n",
    "num_colnames = list(all_features.dtypes[all_features.dtypes != 'object'].index)\n",
    "for cat_colname in cat_colnames:\n",
    "    all_features = make_one_hot(all_features,\n",
    "        list(all_features).index(cat_colname))\n",
    "```\n",
    "\n",
    "At this moment, collect all numerical, non-one-hot columns that still have NULL values. If it is a column indicating quality/condition, replace the NULL values by 0, the lowest rating possible; otherwise, replace NULL by column mean.\n",
    "```python\n",
    "nullc = [c_name for c_name in list(all_features) if all_features[c_name].isnull().values.any()]\n",
    "for colname in nullc:\n",
    "    # If you are one of the columns below, replace NaN by 0\n",
    "    if colname in [\"BsmtQual\", \"BsmtCond\",\n",
    "                    \"FireplaceQu\",\n",
    "                    \"GarageQual\", \"GarageCond\",\n",
    "                    \"PoolQC\"]:\n",
    "        all_features[colname] = all_features[colname].fillna(0)\n",
    "    # Otherwise, replace by mean of the column\n",
    "    else:\n",
    "        col_mean = all_features[colname].mean()\n",
    "        all_features[colname] = all_features[colname].fillna(col_mean)\n",
    "```\n",
    "\n",
    "Finally, normalize all numerical columns:\n",
    "```python\n",
    "for num_colname in num_colnames:\n",
    "    col_mean = all_features[num_colname].mean()\n",
    "    col_se = all_features[num_colname].std()\n",
    "    all_features[num_colname] = (all_features[num_colname] - col_mean) / col_se\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export \n",
    "\n",
    "Convert `pandas.DataFrame` object into numpy array; this is valid because all columns are either one-hot numerical or continuous numerical. Split the composite `all_features` back into training and testing sets, then export the numpy array to binary save files for future loading.\n",
    "```python\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix\n",
    "There are 2 methods frequently used throughout the cleaning process. Their code is posted here:\n",
    "```python\n",
    "def normalize(df, col_idx, scale=True):\n",
    "    # Given a DataFrame object and a column index that points to a\n",
    "    # numerical column, return a NEW copy of the data frame\n",
    "    # with that column normalized (if scale is True) or\n",
    "    # mean centered (if scale is false)\n",
    "    # If there are NA and NaNs, replace them with the mean; this means\n",
    "    # computing the mean without taking into consideration these values\n",
    "    # then assigning the appropriate rows with 0, since the output is\n",
    "    # either mean centered or normalized\n",
    "\n",
    "    # Get a copy of the data frame object and the column out of the\n",
    "    # copies output DF. From now all operations will be done on the\n",
    "    # copy\n",
    "    output_df = df.copy()\n",
    "    target_col = output_df.iloc[:, col_idx]\n",
    "\n",
    "    # Compute the mean and the sample error (divided by n-1)\n",
    "    col_mean = tagret_col.mean()\n",
    "    col_se = target_col.std()\n",
    "    # If scale is set to true, normalize the column to make\n",
    "    # mean 0 and sample error 1. Otherwise, only do mean centering\n",
    "    if scale:\n",
    "        target_col = (target_col - col_mean) / col_se\n",
    "    else:\n",
    "        target_col = (target_col - col_mean)\n",
    "\n",
    "    # Fill the NaNs and NAs by 0 because we have at least mean centered\n",
    "    # the column\n",
    "    target_col.fillna(0)\n",
    "    # Fill the copy with the new column\n",
    "    output_df.iloc[:, col_idx] = target_col\n",
    "    return output_df\n",
    "\n",
    "def make_one_hot(df, col_idx):\n",
    "    # Given a DataFrame object and a column index that points to\n",
    "    # a categorical variables. Return a NEW copy of the data frame\n",
    "    # in which the categorical column is removed, and one-hot columns\n",
    "    # are created and appended to the end\n",
    "\n",
    "    # Get a copy of the data frame for output, get the column\n",
    "    # then drop this column from the output DF\n",
    "    output_df = df.copy()\n",
    "    # When extracting the target column, enforce the dtype \"str\"\n",
    "    target_col = output_df.iloc[:, col_idx].astype(str)\n",
    "    # Extract the column name so that NaNs from different columns\n",
    "    # will not get confused; this means dummy_na should be False\n",
    "    target_colname = list(output_df)[col_idx]\n",
    "    # Replace values within this column by colname_val\n",
    "    target_col[:] = target_colname + \"_\" + target_col\n",
    "    # Drop the categorical column\n",
    "    output_df = output_df.drop(labels=list(output_df)[col_idx],\n",
    "                            axis=1)\n",
    "\n",
    "    # Use pd method to create one-hot, including using NAN as a distinct\n",
    "    # label\n",
    "    one_hot = pd.get_dummies(target_col, dummy_na = False)\n",
    "\n",
    "    # Concatenate the two dfs and return it\n",
    "    return pd.concat([output_df, one_hot], axis=1)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
